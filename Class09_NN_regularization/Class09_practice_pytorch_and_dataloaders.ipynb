{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class09 practice: PyTorch practice, hints and Dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Credits:\n",
    "* First part is based on YSDA [Practical RL course week04 materials](https://github.com/yandexdataschool/Practical_RL/tree/master/week04_%5Brecap%5D_deep_learning).\n",
    "* Second part is based on PyTorch official tutorials and [this kaggle kernel](https://www.kaggle.com/pinocookie/pytorch-dataset-and-dataloader)\n",
    "* Third part is based on PyTorch tutorial by [Stanford CS 231n course](http://cs231n.stanford.edu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](https://pytorch.org/tutorials/_static/pytorch-logo-dark.svg)\n",
    "\n",
    "__This notebook__ will remind you how to use pytorch low and high-level core. You can install it [here](http://pytorch.org/).\n",
    "\n",
    "__Pytorch feels__ differently than other frameworks (like tensorflow/theano) on almost every level. TensorFlow makes your code live in two \"worlds\" simultaneously:  symbolic graphs and actual tensors. First you declare a symbolic \"recipe\" of how to get from inputs to outputs, then feed it with actual minibatches of data.  In pytorch, __there's only one world__: all tensors have a numeric value.\n",
    "\n",
    "You compute outputs on the fly without pre-declaring anything. The code looks exactly as in pure numpy with one exception: pytorch computes gradients for you. And can run stuff on GPU. And has a number of pre-implemented building blocks for your neural nets. [And a few more things.](https://medium.com/towards-data-science/pytorch-vs-tensorflow-spotting-the-difference-25c75777377b)\n",
    "\n",
    "Let's dive into it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T00:59:42.103233Z",
     "start_time": "2020-02-28T00:59:42.099338Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "import torchvision\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Tensormancy\n",
    "\n",
    "__1.1 The [_disclaimer_](https://gist.githubusercontent.com/justheuristic/e2c1fa28ca02670cabc42cacf3902796/raw/fd3d935cef63a01b85ed2790b5c11c370245cbd7/stddisclaimer.h)__\n",
    "\n",
    "Let's write another function, this time in polar coordinates:\n",
    "$$\\rho(\\theta) = (1 + 0.9 \\cdot cos (6 \\cdot \\theta) ) \\cdot (1 + 0.01 \\cdot cos(24 \\cdot \\theta)) \\cdot (0.5 + 0.05 \\cdot cos(200 \\cdot \\theta)) \\cdot (10 + sin(10 \\cdot \\theta))$$\n",
    "\n",
    "\n",
    "Then convert it into cartesian coordinates ([howto](http://www.mathsisfun.com/polar-cartesian-coordinates.html)) and plot the results.\n",
    "\n",
    "Use torch tensors only: no lists, loops, numpy arrays, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T00:13:20.890514Z",
     "start_time": "2020-02-28T00:13:20.639022Z"
    }
   },
   "outputs": [],
   "source": [
    "theta = torch.linspace(-np.pi, np.pi, steps=1000)\n",
    "\n",
    "# compute rho(theta) as per formula above\n",
    "rho = ### YOUR CODE HERE\n",
    "\n",
    "# Now convert polar (rho, theta) pairs into cartesian (x,y) to plot them.\n",
    "x = ### YOUR CODE HERE\n",
    "y = ### YOUR CODE HERE\n",
    "\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.fill(x.numpy(), y.numpy(), color='red')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Using the Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T00:13:20.896055Z",
     "start_time": "2020-02-28T00:13:20.893241Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T00:13:21.223097Z",
     "start_time": "2020-02-28T00:13:21.220643Z"
    }
   },
   "outputs": [],
   "source": [
    "# Uncomment in colab:\n",
    "# !wget https://raw.githubusercontent.com/girafe-ai/ml-course/21f_basic/week0_08_dropout_batchnorm/notmnist.py -nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T08:04:08.525398Z",
     "start_time": "2020-02-28T08:04:08.519240Z"
    }
   },
   "outputs": [],
   "source": [
    "class DatasetMNIST(Dataset):\n",
    "    def __init__(self, path='./notMNIST_small', letters='ABCDEFGHIJ', transform=None):\n",
    "        self.data, self.labels, _ ,_  = load_notmnist(path=path, letters=letters, test_size=0)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # load image as ndarray type (Height * Width * Channels)\n",
    "        # be carefull for converting dtype to np.uint8 [Unsigned integer (0 to 255)]\n",
    "        # in this example, i don't use ToTensor() method of torchvision.transforms\n",
    "        # so you can convert numpy ndarray shape to tensor in PyTorch (H, W, C) --> (C, H, W)\n",
    "        image = self.data[index].transpose(1, 2, 0)\n",
    "        label = self.labels[index]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T00:13:24.681345Z",
     "start_time": "2020-02-28T00:13:21.715775Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data...\n",
      "Extracting ...\n",
      "Parsing...\n",
      "found broken img: ./notMNIST_small\\A\\RGVtb2NyYXRpY2FCb2xkT2xkc3R5bGUgQm9sZC50dGY=.png [it's ok if <10 images are broken]\n",
      "found broken img: ./notMNIST_small\\F\\Q3Jvc3NvdmVyIEJvbGRPYmxpcXVlLnR0Zg==.png [it's ok if <10 images are broken]\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "from notmnist import load_notmnist\n",
    "X_train, y_train, X_test, y_test = load_notmnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T08:04:19.890914Z",
     "start_time": "2020-02-28T08:04:19.336026Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing...\n",
      "found broken img: ./notMNIST_small\\A\\RGVtb2NyYXRpY2FCb2xkT2xkc3R5bGUgQm9sZC50dGY=.png [it's ok if <10 images are broken]\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "full_dataset = DatasetMNIST('./notMNIST_small', 'AB', transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T08:05:36.271686Z",
     "start_time": "2020-02-28T08:05:36.267914Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# we can access and get data with index by __getitem__(index)\n",
    "img, lab = full_dataset.__getitem__(0)\n",
    "\n",
    "print(img.shape)\n",
    "print(type(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T08:05:39.406582Z",
     "start_time": "2020-02-28T08:05:39.402397Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torchvision.transforms.ToTensor()\n",
    "\n",
    "a(img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T00:13:37.378205Z",
     "start_time": "2020-02-28T00:13:37.115219Z"
    }
   },
   "outputs": [],
   "source": [
    "inds = np.random.randint(len(full_dataset), size=2)\n",
    "\n",
    "for i in range(2):\n",
    "    plt.subplot(1, 2, i + 1)\n",
    "    plt.imshow(full_dataset[inds[i]][0].reshape([28,28]))\n",
    "    plt.title(str(full_dataset[inds[i]][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To the DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T00:13:38.561437Z",
     "start_time": "2020-02-28T00:13:38.558371Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(full_dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use dataloader as iterator by using iter() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T00:13:39.386457Z",
     "start_time": "2020-02-28T00:13:39.382386Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.utils.data.dataloader._SingleProcessDataLoaderIter'>\n"
     ]
    }
   ],
   "source": [
    "train_iter = iter(train_loader)\n",
    "print(type(train_iter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at images and labels of batch size by extracting data `.next()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T00:13:40.508098Z",
     "start_time": "2020-02-28T00:13:40.502629Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'_SingleProcessDataLoaderIter' object has no attribute 'next'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[76], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m train_iter\u001b[38;5;241m.\u001b[39mnext()\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages shape on batch size = \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(images\u001b[38;5;241m.\u001b[39msize()))\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels shape on batch size = \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(labels\u001b[38;5;241m.\u001b[39msize()))\n",
      "\u001b[1;31mAttributeError\u001b[0m: '_SingleProcessDataLoaderIter' object has no attribute 'next'"
     ]
    }
   ],
   "source": [
    "images, labels = train_iter.next()\n",
    "# if that does not work then:\n",
    "#images, labels = next(train_iter)\n",
    "\n",
    "print('images shape on batch size = {}'.format(images.size()))\n",
    "print('labels shape on batch size = {}'.format(labels.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T00:13:41.593728Z",
     "start_time": "2020-02-28T00:13:41.506364Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[72], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# make grid takes tensor as arg\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# tensor : (batchsize, channels, height, width)\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m grid \u001b[38;5;241m=\u001b[39m torchvision\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mmake_grid(images\u001b[38;5;241m.\u001b[39mpermute([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m]))\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(grid\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mtranspose((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m)))\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'images' is not defined"
     ]
    }
   ],
   "source": [
    "# make grid takes tensor as arg\n",
    "# tensor : (batchsize, channels, height, width)\n",
    "grid = torchvision.utils.make_grid(images.permute([0, 3, 1, 2]))\n",
    "\n",
    "plt.imshow(grid.numpy().transpose((1, 2, 0)))\n",
    "plt.axis('off')\n",
    "plt.title(labels.numpy());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now with transformations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T00:13:48.795066Z",
     "start_time": "2020-02-28T00:13:46.451771Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset_with_transform = DatasetMNIST(\n",
    "    transform=torchvision.transforms.ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T00:13:48.801336Z",
     "start_time": "2020-02-28T00:13:48.797410Z"
    }
   },
   "outputs": [],
   "source": [
    "img, lab = train_dataset_with_transform.__getitem__(0)\n",
    "\n",
    "print('image shape at the first row : {}'.format(img.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T00:13:52.064233Z",
     "start_time": "2020-02-28T00:13:52.057623Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader_tr = DataLoader(train_dataset_with_transform, batch_size=8, shuffle=True)\n",
    "\n",
    "train_iter_tr = iter(train_loader_tr)\n",
    "print(type(train_iter_tr))\n",
    "\n",
    "images, labels = train_iter_tr.next()\n",
    "\n",
    "print('images shape on batch size = {}'.format(images.size()))\n",
    "print('labels shape on batch size = {}'.format(labels.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T00:13:53.200621Z",
     "start_time": "2020-02-28T00:13:53.062965Z"
    }
   },
   "outputs": [],
   "source": [
    "grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "plt.imshow(grid.numpy().transpose((1, 2, 0)))\n",
    "plt.axis('off')\n",
    "plt.title(labels.numpy());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Composing several transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to take data augmentation, you have to make List using `torchvision.transforms.Compose`\n",
    "\n",
    "```\n",
    "class Compose(object):\n",
    "    \"\"\"Composes several transforms together.\n",
    "    Args:\n",
    "        transforms (list of ``Transform`` objects): list of transforms to compose.\n",
    "    Example:\n",
    "        >>> transforms.Compose([\n",
    "        >>>     transforms.CenterCrop(10),\n",
    "        >>>     transforms.ToTensor(),\n",
    "        >>> ])\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, img):\n",
    "        for t in self.transforms:\n",
    "            img = t(img)\n",
    "        return img\n",
    "\n",
    "    def __repr__(self):\n",
    "        format_string = self.__class__.__name__ + '('\n",
    "        for t in self.transforms:\n",
    "            format_string += '\\n'\n",
    "            format_string += '    {0}'.format(t)\n",
    "        format_string += '\\n)'\n",
    "        return format_string\n",
    "```\n",
    "\n",
    "\n",
    "this function can convert some image by order within `__call__` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T00:13:54.766219Z",
     "start_time": "2020-02-28T00:13:54.762711Z"
    }
   },
   "outputs": [],
   "source": [
    "class Flatten():\n",
    "    def __call__(self, pic):\n",
    "        return pic.flatten()\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '()'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T00:13:55.430127Z",
     "start_time": "2020-02-28T00:13:55.427338Z"
    }
   },
   "outputs": [],
   "source": [
    "a = Flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T00:13:56.147330Z",
     "start_time": "2020-02-28T00:13:56.143060Z"
    }
   },
   "outputs": [],
   "source": [
    "a(img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T00:13:56.918185Z",
     "start_time": "2020-02-28T00:13:56.915283Z"
    }
   },
   "outputs": [],
   "source": [
    "new_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    Flatten()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T09:37:37.781950Z",
     "start_time": "2020-02-28T09:37:37.779388Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T00:56:29.075866Z",
     "start_time": "2020-02-28T00:56:29.071564Z"
    }
   },
   "outputs": [],
   "source": [
    "# use GPU if available\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T09:28:18.459203Z",
     "start_time": "2020-02-28T09:28:18.455997Z"
    }
   },
   "outputs": [],
   "source": [
    "def subset_ind(dataset, ratio: float):\n",
    "#     return ### YOUR CODE HERE\n",
    "    return np.random.choice(len(dataset), size=int(ratio*len(dataset)), replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T09:32:54.001780Z",
     "start_time": "2020-02-28T09:32:51.635588Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = DatasetMNIST(\n",
    "    './notMNIST_small',\n",
    "#     'AB',\n",
    "    transform=new_transform\n",
    ")\n",
    "\n",
    "shrink_inds = subset_ind(dataset, 0.2)\n",
    "dataset = Subset(dataset, shrink_inds)\n",
    "\n",
    "print(f'\\n\\n dataset size: {len(dataset)}, labels: {np.unique(dataset.dataset.labels)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T09:32:54.028315Z",
     "start_time": "2020-02-28T09:32:54.004282Z"
    }
   },
   "outputs": [],
   "source": [
    "val_size = 0.2\n",
    "val_inds = subset_ind(dataset, val_size)\n",
    "\n",
    "train_dataset = Subset(dataset, [i for i in range(len(dataset)) if i not in val_inds])\n",
    "val_dataset = Subset(dataset, val_inds)\n",
    "\n",
    "print(f'  training size: {len(train_dataset)}\\nvalidation size: {len(val_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T09:32:59.926520Z",
     "start_time": "2020-02-28T09:32:59.922784Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T09:33:00.954231Z",
     "start_time": "2020-02-28T09:33:00.947835Z"
    }
   },
   "outputs": [],
   "source": [
    "train_iter = iter(train_loader)\n",
    "print(type(train_iter))\n",
    "\n",
    "images, labels = train_iter.next()\n",
    "\n",
    "print('images shape on batch size = {}'.format(images.size()))\n",
    "print('labels shape on batch size = {}'.format(labels.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T09:35:42.679368Z",
     "start_time": "2020-02-28T09:35:42.676594Z"
    }
   },
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T09:35:44.204284Z",
     "start_time": "2020-02-28T09:35:44.199944Z"
    }
   },
   "outputs": [],
   "source": [
    "# create network again just in case\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(784, 10),\n",
    "    nn.Sigmoid(),\n",
    ")\n",
    "model.to(device, torch.float32)\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T09:33:02.897035Z",
     "start_time": "2020-02-28T09:33:02.884404Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, loss_fn, opt, n_epochs: int):\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    val_accuracy = []\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        ep_train_loss = []\n",
    "        ep_val_loss = []\n",
    "        ep_val_accuracy = []\n",
    "        start_time = time.time()\n",
    "\n",
    "        model.train(True) # enable dropout / batch_norm training behavior\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            # move data to target device\n",
    "            ### YOUR CODE HERE\n",
    "\n",
    "            # train on batch: compute loss, calc grads, perform optimizer step and zero the grads\n",
    "            ### YOUR CODE HERE\n",
    "            ep_train_loss.append(loss.item())\n",
    "\n",
    "        model.train(False) # disable dropout / use averages for batch_norm\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                # move data to target device\n",
    "                ### YOUR CODE HERE\n",
    "\n",
    "                # compute predictions\n",
    "                ### YOUR CODE HERE\n",
    "                ep_val_loss.append(### YOUR CODE HERE)\n",
    "                y_pred = ### YOUR CODE HERE\n",
    "                ep_val_accuracy.append(### YOUR CODE HERE)\n",
    "\n",
    "        # print the results for this epoch:\n",
    "        print(f'Epoch {epoch + 1} of {n_epochs} took {time.time() - start_time:.3f}s')\n",
    "\n",
    "        train_loss.append(np.mean(ep_train_loss))\n",
    "        val_loss.append(np.mean(ep_val_loss))\n",
    "        val_accuracy.append(np.mean(ep_val_accuracy))\n",
    "        \n",
    "        print(f\"\\t  training loss: {train_loss[-1]:.6f}\")\n",
    "        print(f\"\\tvalidation loss: {val_loss[-1]:.6f}\")\n",
    "        print(f\"\\tvalidation accuracy: {val_accuracy[-1]:.3f}\")\n",
    "\n",
    "    return train_loss, val_loss, val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T09:33:33.252494Z",
     "start_time": "2020-02-28T09:33:28.712014Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 30\n",
    "\n",
    "train_loss, val_loss, val_accuracy = train_model(model, train_loader, val_loader, loss_func, opt, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T09:33:35.242213Z",
     "start_time": "2020-02-28T09:33:35.237045Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_train_process(train_loss, val_loss, val_accuracy):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "    axes[0].set_title('Loss')\n",
    "    axes[0].plot(train_loss, label='train')\n",
    "    axes[0].plot(val_loss, label='validation')\n",
    "    axes[0].legend()\n",
    "\n",
    "    axes[1].set_title('Validation accuracy')\n",
    "    axes[1].plot(val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T09:33:36.057391Z",
     "start_time": "2020-02-28T09:33:35.611228Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_train_process(train_loss, val_loss, val_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T09:44:50.420339Z",
     "start_time": "2020-02-28T09:44:50.406364Z"
    }
   },
   "outputs": [],
   "source": [
    "# create network again just in case\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(784, 500),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(500, 200),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(200, 10),\n",
    "    nn.Sigmoid(),\n",
    ")\n",
    "model.to(device, torch.float32)\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T09:45:08.145156Z",
     "start_time": "2020-02-28T09:44:52.924801Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 30\n",
    "\n",
    "train_loss, val_loss, val_accuracy = train_model(model, train_loader, val_loader, loss_func, opt, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T09:45:13.396284Z",
     "start_time": "2020-02-28T09:45:13.032994Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_train_process(train_loss, val_loss, val_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your turn\n",
    "Try to add some additional transformations (e.g. random crop, rotation etc.) and train your model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batchnorm try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Save the model (model checkpointing)\n",
    "\n",
    "Now we have trained a model! Obviously we do not want to retrain the model everytime we want to use it. Plus if you are training a super big model, you probably want to save checkpoint periodically so that you can always fall back to the last checkpoint in case something bad happened or you simply want to test models at different training iterations.\n",
    "\n",
    "Model checkpointing is fairly simple in PyTorch. First, we define a helper function that can save a model to the disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(checkpoint_path, model, optimizer):\n",
    "    # state_dict: a Python dictionary object that:\n",
    "    # - for a model, maps each layer to its parameter tensor;\n",
    "    # - for an optimizer, contains info about the optimizer’s states and hyperparameters used.\n",
    "    state = {\n",
    "        'state_dict': model.state_dict(),\n",
    "        'optimizer' : optimizer.state_dict()}\n",
    "    torch.save(state, checkpoint_path)\n",
    "    print('model saved to %s' % checkpoint_path)\n",
    "    \n",
    "def load_checkpoint(checkpoint_path, model, optimizer):\n",
    "    state = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(state['state_dict'])\n",
    "    optimizer.load_state_dict(state['optimizer'])\n",
    "    print('model loaded from %s' % checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a brand new model\n",
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "# Testing -- you should get a pretty poor performance since the model hasn't learned anything yet.\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a training loop with model checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_save(epoch, save_interval, log_interval=100):\n",
    "    model.train()  # set training mode\n",
    "    iteration = 0\n",
    "    for ep in range(epoch):\n",
    "        for batch_idx, (data, target) in enumerate(trainset_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if iteration % log_interval == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    ep, batch_idx * len(data), len(trainset_loader.dataset),\n",
    "                    100. * batch_idx / len(trainset_loader), loss.item()))\n",
    "            # different from before: saving model checkpoints\n",
    "            if iteration % save_interval == 0 and iteration > 0:\n",
    "                save_checkpoint('mnist-%i.pth' % iteration, model, optimizer)\n",
    "            iteration += 1\n",
    "        test()\n",
    "    \n",
    "    # save the final model\n",
    "    save_checkpoint('mnist-%i.pth' % iteration, model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_save(5, save_interval=500, log_interval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls mnist*.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new model\n",
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "# load from the final checkpoint\n",
    "load_checkpoint('<CHECKPOINT NAME>', model, optimizer)\n",
    "# should give you the final model accuracy\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "### More about pytorch:\n",
    "* Using torch on GPU and multi-GPU - [link](http://pytorch.org/docs/master/notes/cuda.html)\n",
    "* More tutorials on pytorch - [link](http://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html)\n",
    "* Pytorch examples - a repo that implements many cool DL models in pytorch - [link](https://github.com/pytorch/examples)\n",
    "* Practical pytorch - a repo that implements some... other cool DL models... yes, in pytorch - [link](https://github.com/spro/practical-pytorch)\n",
    "* And some more - [link](https://www.reddit.com/r/pytorch/comments/6z0yeo/pytorch_and_pytorch_tricks_for_kaggle/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus section: vanishing gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this notebook, we will demonstrate the difference between using sigmoid and ReLU nonlinearities in a simple neural network with two hidden layers. This notebook is built off of a minimal net demo done by Andrej Karpathy for CS 231n, which you can check out here: http://cs231n.github.io/neural-networks-case-study/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading extenrnal modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate random data -- not linearly separable \n",
    "np.random.seed(0)\n",
    "N = 100 # number of points per class\n",
    "D = 2 # dimensionality\n",
    "K = 3 # number of classes\n",
    "X = np.zeros((N*K,D))\n",
    "num_train_examples = X.shape[0]\n",
    "y = np.zeros(N*K, dtype='uint8')\n",
    "for j in range(K):\n",
    "    ix = range(N*j,N*(j+1))\n",
    "    r = np.linspace(0.0,1,N) # radius\n",
    "    t = np.linspace(j*4,(j+1)*4,N) + np.random.randn(N)*0.2 # theta\n",
    "    X[ix] = np.c_[r*np.sin(t), r*np.cos(t)]\n",
    "    y[ix] = j\n",
    "fig = plt.figure()\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap=plt.cm.Spectral)\n",
    "plt.xlim([-1,1])\n",
    "plt.ylim([-1,1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sigmoid function \"squashes\" inputs to lie between 0 and 1. Unfortunately, this means that for inputs with sigmoid output close to 0 or 1, the gradient with respect to those inputs are close to zero. This leads to the phenomenon of vanishing gradients, where gradients drop close to zero, and the net does not learn well.\n",
    "\n",
    "On the other hand, the relu function (max(0, x)) does not saturate with input size. Plot these functions to gain intution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    x = 1/(1+np.exp(-x))\n",
    "    return x\n",
    "\n",
    "def sigmoid_grad(x):\n",
    "    return (x)*(1-x)\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0,x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try and see now how the two kinds of nonlinearities change deep neural net training in practice. Below, we build a very simple neural net with three layers (two hidden layers), for which you can swap out ReLU/ sigmoid nonlinearities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to train a three layer neural net with either RELU or sigmoid nonlinearity via vanilla grad descent\n",
    "\n",
    "def three_layer_net(NONLINEARITY,X,y, model, step_size, reg):\n",
    "    #parameter initialization\n",
    "    \n",
    "    h= model['h']\n",
    "    h2= model['h2']\n",
    "    W1= model['W1']\n",
    "    W2= model['W2']\n",
    "    W3= model['W3']\n",
    "    b1= model['b1']\n",
    "    b2= model['b2']\n",
    "    b3= model['b3']\n",
    "    \n",
    "    \n",
    "    # some hyperparameters\n",
    "\n",
    "\n",
    "    # gradient descent loop\n",
    "    num_examples = X.shape[0]\n",
    "    plot_array_1=[]\n",
    "    plot_array_2=[]\n",
    "    for i in range(50000):\n",
    "\n",
    "        #FOWARD PROP\n",
    "\n",
    "        if NONLINEARITY== 'RELU':\n",
    "            hidden_layer = relu(np.dot(X, W1) + b1)\n",
    "            hidden_layer2 = relu(np.dot(hidden_layer, W2) + b2)\n",
    "            scores = np.dot(hidden_layer2, W3) + b3\n",
    "\n",
    "        elif NONLINEARITY == 'SIGM':\n",
    "            hidden_layer = sigmoid(np.dot(X, W1) + b1)\n",
    "            hidden_layer2 = sigmoid(np.dot(hidden_layer, W2) + b2)\n",
    "            scores = np.dot(hidden_layer2, W3) + b3\n",
    "\n",
    "        exp_scores = np.exp(scores)\n",
    "        probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True) # [N x K]\n",
    "\n",
    "        # compute the loss: average cross-entropy loss and regularization\n",
    "        corect_logprobs = -np.log(probs[range(num_examples),y])\n",
    "        data_loss = np.sum(corect_logprobs)/num_examples\n",
    "        reg_loss = 0.5*reg*np.sum(W1*W1) + 0.5*reg*np.sum(W2*W2)+ 0.5*reg*np.sum(W3*W3)\n",
    "        loss = data_loss + reg_loss\n",
    "        if i % 1000 == 0:\n",
    "            print(\"iteration %d: loss %f\" % (i, loss))\n",
    "\n",
    "\n",
    "        # compute the gradient on scores\n",
    "        dscores = probs\n",
    "        dscores[range(num_examples),y] -= 1\n",
    "        dscores /= num_examples\n",
    "\n",
    " \n",
    "        # BACKPROP HERE\n",
    "        dW3 = (hidden_layer2.T).dot(dscores)\n",
    "        db3 = np.sum(dscores, axis=0, keepdims=True)\n",
    "\n",
    "\n",
    "        if NONLINEARITY == 'RELU':\n",
    "\n",
    "            #backprop ReLU nonlinearity here\n",
    "            dhidden2 = np.dot(dscores, W3.T)\n",
    "            dhidden2[hidden_layer2 <= 0] = 0\n",
    "            dW2 =  np.dot( hidden_layer.T, dhidden2)\n",
    "            plot_array_2.append(np.sum(np.abs(dW2))/np.sum(np.abs(dW2.shape)))\n",
    "            db2 = np.sum(dhidden2, axis=0)\n",
    "            dhidden = np.dot(dhidden2, W2.T)\n",
    "            dhidden[hidden_layer <= 0] = 0\n",
    "            \n",
    "        elif NONLINEARITY == 'SIGM':\n",
    "\n",
    "            #backprop sigmoid nonlinearity here\n",
    "            dhidden2 = dscores.dot(W3.T)*sigmoid_grad(hidden_layer2)\n",
    "            dW2 = (hidden_layer.T).dot(dhidden2)\n",
    "            plot_array_2.append(np.sum(np.abs(dW2))/np.sum(np.abs(dW2.shape)))\n",
    "            db2 = np.sum(dhidden2, axis=0)\n",
    "            dhidden = dhidden2.dot(W2.T)*sigmoid_grad(hidden_layer)\n",
    "\n",
    "        \n",
    "        dW1 =  np.dot(X.T, dhidden)\n",
    "        plot_array_1.append(np.sum(np.abs(dW1))/np.sum(np.abs(dW1.shape)))\n",
    "        db1 = np.sum(dhidden, axis=0)\n",
    "\n",
    "        # add regularization\n",
    "        dW3+= reg * W3\n",
    "        dW2 += reg * W2\n",
    "        dW1 += reg * W1\n",
    "        \n",
    "        #option to return loss, grads -- uncomment next comment\n",
    "        grads={}\n",
    "        grads['W1']=dW1\n",
    "        grads['W2']=dW2\n",
    "        grads['W3']=dW3\n",
    "        grads['b1']=db1\n",
    "        grads['b2']=db2\n",
    "        grads['b3']=db3\n",
    "        #return loss, grads\n",
    "        \n",
    "        \n",
    "        # update\n",
    "        W1 += -step_size * dW1\n",
    "        b1 += -step_size * db1\n",
    "        W2 += -step_size * dW2\n",
    "        b2 += -step_size * db2\n",
    "        W3 += -step_size * dW3\n",
    "        b3 += -step_size * db3\n",
    "    # evaluate training set accuracy\n",
    "    if NONLINEARITY == 'RELU':\n",
    "        hidden_layer = relu(np.dot(X, W1) + b1)\n",
    "        hidden_layer2 = relu(np.dot(hidden_layer, W2) + b2)\n",
    "    elif NONLINEARITY == 'SIGM':\n",
    "        hidden_layer = sigmoid(np.dot(X, W1) + b1)\n",
    "        hidden_layer2 = sigmoid(np.dot(hidden_layer, W2) + b2)\n",
    "    scores = np.dot(hidden_layer2, W3) + b3\n",
    "    predicted_class = np.argmax(scores, axis=1)\n",
    "    print('training accuracy: %.2f' % (np.mean(predicted_class == y)))\n",
    "    #return cost, grads\n",
    "    return plot_array_1, plot_array_2, W1, W2, W3, b1, b2, b3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train net with sigmoid nonlinearity first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize toy model, train sigmoid net\n",
    "\n",
    "N = 100 # number of points per class\n",
    "D = 2 # dimensionality\n",
    "K = 3 # number of classes\n",
    "h=50\n",
    "h2=50\n",
    "num_train_examples = X.shape[0]\n",
    "\n",
    "model={}\n",
    "model['h'] = h # size of hidden layer 1\n",
    "model['h2']= h2# size of hidden layer 2\n",
    "model['W1']= 0.1 * np.random.randn(D,h)\n",
    "model['b1'] = np.zeros((1,h))\n",
    "model['W2'] = 0.1 * np.random.randn(h,h2)\n",
    "model['b2']= np.zeros((1,h2))\n",
    "model['W3'] = 0.1 * np.random.randn(h2,K)\n",
    "model['b3'] = np.zeros((1,K))\n",
    "\n",
    "(sigm_array_1, sigm_array_2, s_W1, s_W2,s_W3, s_b1, s_b2,s_b3) = three_layer_net('SIGM', X,y,model, step_size=1e-1, reg=1e-3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now train net with ReLU nonlinearity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Re-initialize model, train relu net\n",
    "\n",
    "model={}\n",
    "model['h'] = h # size of hidden layer 1\n",
    "model['h2']= h2# size of hidden layer 2\n",
    "model['W1']= 0.1 * np.random.randn(D,h)\n",
    "model['b1'] = np.zeros((1,h))\n",
    "model['W2'] = 0.1 * np.random.randn(h,h2)\n",
    "model['b2']= np.zeros((1,h2))\n",
    "model['W3'] = 0.1 * np.random.randn(h2,K)\n",
    "model['b3'] = np.zeros((1,K))\n",
    "\n",
    "(relu_array_1, relu_array_2, r_W1, r_W2,r_W3, r_b1, r_b2,r_b3) = three_layer_net('RELU', X,y,model, step_size=1e-1, reg=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Vanishing Gradient Issue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the sum of the magnitude of gradients for the weights between hidden layers as a cheap heuristic to measure speed of learning (you can also use the magnitude of gradients for each neuron in the hidden layer here). Intuitevely, when the magnitude of the gradients of the weight vectors or of each neuron are large, the net is learning faster. (NOTE: For our net, each hidden layer has the same number of neurons. If you want to play around with this, make sure to adjust the heuristic to account for the number of neurons in the layer). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams.update({'figure.figsize': (12, 8), 'font.size': 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(sigm_array_1))\n",
    "plt.plot(np.array(sigm_array_2))\n",
    "plt.title('Sum of magnitudes of gradients -- SIGM weights')\n",
    "plt.legend((\"sigm first layer\", \"sigm second layer\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(relu_array_1))\n",
    "plt.plot(np.array(relu_array_2))\n",
    "plt.title('Sum of magnitudes of gradients -- ReLU weights')\n",
    "plt.legend((\"relu first layer\", \"relu second layer\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overlaying the two plots to compare\n",
    "plt.plot(np.array(relu_array_1))\n",
    "plt.plot(np.array(relu_array_2))\n",
    "plt.plot(np.array(sigm_array_1))\n",
    "plt.plot(np.array(sigm_array_2))\n",
    "plt.title('Sum of magnitudes of gradients -- hidden layer neurons')\n",
    "plt.legend((\"relu first layer\", \"relu second layer\",\"sigm first layer\", \"sigm second layer\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feel free to play around with this notebook to gain intuition. Things you might want to try:\n",
    "\n",
    "- Adding additional layers to the nets and seeing how early layers continue to train slowly for the sigmoid net \n",
    "- Experiment with hyperparameter tuning for the nets -- changing regularization and gradient descent step size\n",
    "- Experiment with different nonlinearities -- Leaky ReLU, Maxout. How quickly do different layers learn now?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see how well each classifier does in terms of distinguishing the toy data classes. As expected, since the ReLU net trains faster, for a set number of epochs it performs better compared to the sigmoid net. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the classifiers- SIGMOID\n",
    "h = 0.02\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "Z = np.dot(sigmoid(np.dot(sigmoid(np.dot(np.c_[xx.ravel(), yy.ravel()], s_W1) + s_b1), s_W2) + s_b2), s_W3) + s_b3\n",
    "Z = np.argmax(Z, axis=1)\n",
    "Z = Z.reshape(xx.shape)\n",
    "fig = plt.figure()\n",
    "plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral, alpha=0.8)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap=plt.cm.Spectral)\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the classifiers-- RELU\n",
    "h = 0.02\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "Z = np.dot(relu(np.dot(relu(np.dot(np.c_[xx.ravel(), yy.ravel()], r_W1) + r_b1), r_W2) + r_b2), r_W3) + r_b3\n",
    "Z = np.argmax(Z, axis=1)\n",
    "Z = Z.reshape(xx.shape)\n",
    "fig = plt.figure()\n",
    "plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral, alpha=0.8)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap=plt.cm.Spectral)\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
